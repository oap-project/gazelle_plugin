-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 71


-- !query
select to_json(named_struct('a', 1, 'b', 2))
-- !query schema
struct<to_json(named_struct(a, 1, b, 2)):string>
-- !query output
{"a":1,"b":2}


-- !query
select to_json(named_struct('time', to_timestamp('2015-08-26', 'yyyy-MM-dd')), map('timestampFormat', 'dd/MM/yyyy'))
-- !query schema
struct<to_json(named_struct(time, to_timestamp(2015-08-26, yyyy-MM-dd))):string>
-- !query output
{"time":"26/08/2015"}


-- !query
select to_json(array(named_struct('a', 1, 'b', 2)))
-- !query schema
struct<to_json(array(named_struct(a, 1, b, 2))):string>
-- !query output
[{"a":1,"b":2}]


-- !query
select to_json(map(named_struct('a', 1, 'b', 2), named_struct('a', 1, 'b', 2)))
-- !query schema
struct<to_json(map(named_struct(a, 1, b, 2), named_struct(a, 1, b, 2))):string>
-- !query output
{"[1,2]":{"a":1,"b":2}}


-- !query
select to_json(map('a', named_struct('a', 1, 'b', 2)))
-- !query schema
struct<to_json(map(a, named_struct(a, 1, b, 2))):string>
-- !query output
{"a":{"a":1,"b":2}}


-- !query
select to_json(map('a', 1))
-- !query schema
struct<to_json(map(a, 1)):string>
-- !query output
{"a":1}


-- !query
select to_json(array(map('a',1)))
-- !query schema
struct<to_json(array(map(a, 1))):string>
-- !query output
[{"a":1}]


-- !query
select to_json(array(map('a',1), map('b',2)))
-- !query schema
struct<to_json(array(map(a, 1), map(b, 2))):string>
-- !query output
[{"a":1},{"b":2}]


-- !query
select to_json(named_struct('a', 1, 'b', 2), named_struct('mode', 'PERMISSIVE'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Must use a map() function for options; line 1 pos 7


-- !query
select to_json(named_struct('a', 1, 'b', 2), map('mode', 1))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
A type of keys and values in map() must be string, but got map<string,int>; line 1 pos 7


-- !query
select to_json()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Invalid number of arguments for function to_json. Expected: one of 1 and 2; Found: 0; line 1 pos 7


-- !query
select from_json('{"a":1}', 'a INT')
-- !query schema
struct<from_json({"a":1}):struct<a:int>>
-- !query output
{"a":1}


-- !query
select from_json('{"time":"26/08/2015"}', 'time Timestamp', map('timestampFormat', 'dd/MM/yyyy'))
-- !query schema
struct<from_json({"time":"26/08/2015"}):struct<time:timestamp>>
-- !query output
{"time":2015-08-26 00:00:00}


-- !query
select from_json('{"a":1}', 1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
The expression '1' is not a valid schema string.; line 1 pos 7


-- !query
select from_json('{"a":1}', 'a InvalidType')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Cannot parse the data type: 
extraneous input 'InvalidType' expecting <EOF>(line 1, pos 2)

== SQL ==
a InvalidType
--^^^

Failed fallback parsing: 
DataType invalidtype is not supported.(line 1, pos 2)

== SQL ==
a InvalidType
--^^^
; line 1 pos 7


-- !query
select from_json('{"a":1}', 'a INT', named_struct('mode', 'PERMISSIVE'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Must use a map() function for options; line 1 pos 7


-- !query
select from_json('{"a":1}', 'a INT', map('mode', 1))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
A type of keys and values in map() must be string, but got map<string,int>; line 1 pos 7


-- !query
select from_json()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Invalid number of arguments for function from_json. Expected: one of 2 and 3; Found: 0; line 1 pos 7


-- !query
SELECT json_tuple('{"a" : 1, "b" : 2}', CAST(NULL AS STRING), 'b', CAST(NULL AS STRING), 'a')
-- !query schema
struct<c0:string,c1:string,c2:string,c3:string>
-- !query output
NULL	2	NULL	1


-- !query
CREATE TEMPORARY VIEW jsonTable(jsonField, a) AS SELECT * FROM VALUES ('{"a": 1, "b": 2}', 'a')
-- !query schema
struct<>
-- !query output



-- !query
SELECT json_tuple(jsonField, 'b', CAST(NULL AS STRING), a) FROM jsonTable
-- !query schema
struct<c0:string,c1:string,c2:string>
-- !query output
2	NULL	1


-- !query
DROP VIEW IF EXISTS jsonTable
-- !query schema
struct<>
-- !query output



-- !query
select from_json('{"a":1, "b":2}', 'map<string, int>')
-- !query schema
struct<entries:map<string,int>>
-- !query output
{"a":1,"b":2}


-- !query
select from_json('{"a":1, "b":"2"}', 'struct<a:int,b:string>')
-- !query schema
struct<from_json({"a":1, "b":"2"}):struct<a:int,b:string>>
-- !query output
{"a":1,"b":"2"}


-- !query
select schema_of_json('{"c1":0, "c2":[1]}')
-- !query schema
struct<schema_of_json({"c1":0, "c2":[1]}):string>
-- !query output
STRUCT<`c1`: BIGINT, `c2`: ARRAY<BIGINT>>


-- !query
select from_json('{"c1":[1, 2, 3]}', schema_of_json('{"c1":[0]}'))
-- !query schema
struct<from_json({"c1":[1, 2, 3]}):struct<c1:array<bigint>>>
-- !query output
{"c1":[1,2,3]}


-- !query
select from_json('[1, 2, 3]', 'array<int>')
-- !query schema
struct<from_json([1, 2, 3]):array<int>>
-- !query output
[1,2,3]


-- !query
select from_json('[1, "2", 3]', 'array<int>')
-- !query schema
struct<from_json([1, "2", 3]):array<int>>
-- !query output
NULL


-- !query
select from_json('[1, 2, null]', 'array<int>')
-- !query schema
struct<from_json([1, 2, null]):array<int>>
-- !query output
[1,2,null]


-- !query
select from_json('[{"a": 1}, {"a":2}]', 'array<struct<a:int>>')
-- !query schema
struct<from_json([{"a": 1}, {"a":2}]):array<struct<a:int>>>
-- !query output
[{"a":1},{"a":2}]


-- !query
select from_json('{"a": 1}', 'array<struct<a:int>>')
-- !query schema
struct<from_json({"a": 1}):array<struct<a:int>>>
-- !query output
[{"a":1}]


-- !query
select from_json('[null, {"a":2}]', 'array<struct<a:int>>')
-- !query schema
struct<from_json([null, {"a":2}]):array<struct<a:int>>>
-- !query output
[null,{"a":2}]


-- !query
select from_json('[{"a": 1}, {"b":2}]', 'array<map<string,int>>')
-- !query schema
struct<from_json([{"a": 1}, {"b":2}]):array<map<string,int>>>
-- !query output
[{"a":1},{"b":2}]


-- !query
select from_json('[{"a": 1}, 2]', 'array<map<string,int>>')
-- !query schema
struct<from_json([{"a": 1}, 2]):array<map<string,int>>>
-- !query output
NULL


-- !query
select from_json('{"d": "2012-12-15", "t": "2012-12-15 15:15:15"}', 'd date, t timestamp')
-- !query schema
struct<from_json({"d": "2012-12-15", "t": "2012-12-15 15:15:15"}):struct<d:date,t:timestamp>>
-- !query output
{"d":2012-12-15,"t":2012-12-15 15:15:15}


-- !query
select from_json(
  '{"d": "12/15 2012", "t": "12/15 2012 15:15:15"}',
  'd date, t timestamp',
  map('dateFormat', 'MM/dd yyyy', 'timestampFormat', 'MM/dd yyyy HH:mm:ss'))
-- !query schema
struct<from_json({"d": "12/15 2012", "t": "12/15 2012 15:15:15"}):struct<d:date,t:timestamp>>
-- !query output
{"d":2012-12-15,"t":2012-12-15 15:15:15}


-- !query
select from_json(
  '{"d": "02-29"}',
  'd date',
  map('dateFormat', 'MM-dd'))
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
You may get a different result due to the upgrading of Spark 3.0: Fail to parse '02-29' in the new parser. You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0, or set to CORRECTED and treat it as an invalid datetime string.


-- !query
select from_json(
  '{"t": "02-29"}',
  't timestamp',
  map('timestampFormat', 'MM-dd'))
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
You may get a different result due to the upgrading of Spark 3.0: Fail to parse '02-29' in the new parser. You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0, or set to CORRECTED and treat it as an invalid datetime string.


-- !query
select to_json(array('1', '2', '3'))
-- !query schema
struct<to_json(array(1, 2, 3)):string>
-- !query output
["1","2","3"]


-- !query
select to_json(array(array(1, 2, 3), array(4)))
-- !query schema
struct<to_json(array(array(1, 2, 3), array(4))):string>
-- !query output
[[1,2,3],[4]]


-- !query
select schema_of_json('{"c1":1}', map('primitivesAsString', 'true'))
-- !query schema
struct<schema_of_json({"c1":1}):string>
-- !query output
STRUCT<`c1`: STRING>


-- !query
select schema_of_json('{"c1":01, "c2":0.1}', map('allowNumericLeadingZeros', 'true', 'prefersDecimal', 'true'))
-- !query schema
struct<schema_of_json({"c1":01, "c2":0.1}):string>
-- !query output
STRUCT<`c1`: BIGINT, `c2`: DECIMAL(1,1)>


-- !query
select schema_of_json(null)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'schema_of_json(NULL)' due to data type mismatch: The input json should be a foldable string expression and not null; however, got NULL.; line 1 pos 7


-- !query
CREATE TEMPORARY VIEW jsonTable(jsonField, a) AS SELECT * FROM VALUES ('{"a": 1, "b": 2}', 'a')
-- !query schema
struct<>
-- !query output



-- !query
SELECT schema_of_json(jsonField) FROM jsonTable
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'schema_of_json(jsontable.`jsonField`)' due to data type mismatch: The input json should be a foldable string expression and not null; however, got jsontable.`jsonField`.; line 1 pos 7


-- !query
select json_array_length(null)
-- !query schema
struct<json_array_length(CAST(NULL AS STRING)):int>
-- !query output
NULL


-- !query
select json_array_length(2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'json_array_length(2)' due to data type mismatch: argument 1 requires string type, however, '2' is of int type.; line 1 pos 7


-- !query
select json_array_length()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Invalid number of arguments for function json_array_length. Expected: 1; Found: 0; line 1 pos 7


-- !query
select json_array_length('')
-- !query schema
struct<json_array_length():int>
-- !query output
NULL


-- !query
select json_array_length('[]')
-- !query schema
struct<json_array_length([]):int>
-- !query output
0


-- !query
select json_array_length('[1,2,3]')
-- !query schema
struct<json_array_length([1,2,3]):int>
-- !query output
3


-- !query
select json_array_length('[[1,2],[5,6,7]]')
-- !query schema
struct<json_array_length([[1,2],[5,6,7]]):int>
-- !query output
2


-- !query
select json_array_length('[{"a":123},{"b":"hello"}]')
-- !query schema
struct<json_array_length([{"a":123},{"b":"hello"}]):int>
-- !query output
2


-- !query
select json_array_length('[1,2,3,[33,44],{"key":[2,3,4]}]')
-- !query schema
struct<json_array_length([1,2,3,[33,44],{"key":[2,3,4]}]):int>
-- !query output
5


-- !query
select json_array_length('{"key":"not a json array"}')
-- !query schema
struct<json_array_length({"key":"not a json array"}):int>
-- !query output
NULL


-- !query
select json_array_length('[1,2,3,4,5')
-- !query schema
struct<json_array_length([1,2,3,4,5):int>
-- !query output
NULL


-- !query
select json_object_keys()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Invalid number of arguments for function json_object_keys. Expected: 1; Found: 0; line 1 pos 7


-- !query
select json_object_keys(null)
-- !query schema
struct<json_object_keys(CAST(NULL AS STRING)):array<string>>
-- !query output
NULL


-- !query
select json_object_keys(200)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'json_object_keys(200)' due to data type mismatch: argument 1 requires string type, however, '200' is of int type.; line 1 pos 7


-- !query
select json_object_keys('')
-- !query schema
struct<json_object_keys():array<string>>
-- !query output
NULL


-- !query
select json_object_keys('{}')
-- !query schema
struct<json_object_keys({}):array<string>>
-- !query output
[]


-- !query
select json_object_keys('{"key": 1}')
-- !query schema
struct<json_object_keys({"key": 1}):array<string>>
-- !query output
["key"]


-- !query
select json_object_keys('{"key": "value", "key2": 2}')
-- !query schema
struct<json_object_keys({"key": "value", "key2": 2}):array<string>>
-- !query output
["key","key2"]


-- !query
select json_object_keys('{"arrayKey": [1, 2, 3]}')
-- !query schema
struct<json_object_keys({"arrayKey": [1, 2, 3]}):array<string>>
-- !query output
["arrayKey"]


-- !query
select json_object_keys('{"key":[1,2,3,{"key":"value"},[1,2,3]]}')
-- !query schema
struct<json_object_keys({"key":[1,2,3,{"key":"value"},[1,2,3]]}):array<string>>
-- !query output
["key"]


-- !query
select json_object_keys('{"f1":"abc","f2":{"f3":"a", "f4":"b"}}')
-- !query schema
struct<json_object_keys({"f1":"abc","f2":{"f3":"a", "f4":"b"}}):array<string>>
-- !query output
["f1","f2"]


-- !query
select json_object_keys('{"k1": [1, 2, {"key": 5}], "k2": {"key2": [1, 2]}}')
-- !query schema
struct<json_object_keys({"k1": [1, 2, {"key": 5}], "k2": {"key2": [1, 2]}}):array<string>>
-- !query output
["k1","k2"]


-- !query
select json_object_keys('{[1,2]}')
-- !query schema
struct<json_object_keys({[1,2]}):array<string>>
-- !query output
NULL


-- !query
select json_object_keys('{"key": 45, "random_string"}')
-- !query schema
struct<json_object_keys({"key": 45, "random_string"}):array<string>>
-- !query output
NULL


-- !query
select json_object_keys('[1, 2, 3]')
-- !query schema
struct<json_object_keys([1, 2, 3]):array<string>>
-- !query output
NULL


-- !query
DROP VIEW IF EXISTS jsonTable
-- !query schema
struct<>
-- !query output

