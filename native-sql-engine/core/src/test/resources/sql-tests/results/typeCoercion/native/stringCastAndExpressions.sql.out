-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 32


-- !query
CREATE TEMPORARY VIEW t AS SELECT 'aa' as a
-- !query schema
struct<>
-- !query output



-- !query
select cast(a as byte) from t
-- !query schema
struct<a:tinyint>
-- !query output
NULL


-- !query
select cast(a as short) from t
-- !query schema
struct<a:smallint>
-- !query output
NULL


-- !query
select cast(a as int) from t
-- !query schema
struct<a:int>
-- !query output
NULL


-- !query
select cast(a as long) from t
-- !query schema
struct<a:bigint>
-- !query output
NULL


-- !query
select cast(a as float) from t
-- !query schema
struct<a:float>
-- !query output
NULL


-- !query
select cast(a as double) from t
-- !query schema
struct<a:double>
-- !query output
NULL


-- !query
select cast(a as decimal) from t
-- !query schema
struct<a:decimal(10,0)>
-- !query output
NULL


-- !query
select cast(a as boolean) from t
-- !query schema
struct<a:boolean>
-- !query output
NULL


-- !query
select cast(a as timestamp) from t
-- !query schema
struct<a:timestamp>
-- !query output
NULL


-- !query
select cast(a as date) from t
-- !query schema
struct<a:date>
-- !query output
NULL


-- !query
select cast(a as binary) from t
-- !query schema
struct<a:binary>
-- !query output
aa


-- !query
select cast(a as array<string>) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 't.`a`' due to data type mismatch: cannot cast string to array<string>; line 1 pos 7


-- !query
select cast(a as struct<s:string>) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 't.`a`' due to data type mismatch: cannot cast string to struct<s:string>; line 1 pos 7


-- !query
select cast(a as map<string, string>) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 't.`a`' due to data type mismatch: cannot cast string to map<string,string>; line 1 pos 7


-- !query
select to_timestamp(a) from t
-- !query schema
struct<to_timestamp(a):timestamp>
-- !query output
NULL


-- !query
select to_timestamp('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
You may get a different result due to the upgrading of Spark 3.0: Fail to recognize 'aa' pattern in the DateTimeFormatter. 1) You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0. 2) You can form a valid datetime pattern with the guide from https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html


-- !query
select to_unix_timestamp(a) from t
-- !query schema
struct<to_unix_timestamp(a, yyyy-MM-dd HH:mm:ss):bigint>
-- !query output
NULL


-- !query
select to_unix_timestamp('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
You may get a different result due to the upgrading of Spark 3.0: Fail to recognize 'aa' pattern in the DateTimeFormatter. 1) You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0. 2) You can form a valid datetime pattern with the guide from https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html


-- !query
select unix_timestamp(a) from t
-- !query schema
struct<unix_timestamp(a, yyyy-MM-dd HH:mm:ss):bigint>
-- !query output
NULL


-- !query
select unix_timestamp('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
You may get a different result due to the upgrading of Spark 3.0: Fail to recognize 'aa' pattern in the DateTimeFormatter. 1) You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0. 2) You can form a valid datetime pattern with the guide from https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html


-- !query
select from_unixtime(a) from t
-- !query schema
struct<from_unixtime(CAST(a AS BIGINT), yyyy-MM-dd HH:mm:ss):string>
-- !query output
NULL


-- !query
select from_unixtime('2018-01-01', a) from t
-- !query schema
struct<from_unixtime(CAST(2018-01-01 AS BIGINT), a):string>
-- !query output
NULL


-- !query
select next_day(a, 'MO') from t
-- !query schema
struct<next_day(CAST(a AS DATE), MO):date>
-- !query output
NULL


-- !query
select next_day('2018-01-01', a) from t
-- !query schema
struct<next_day(CAST(2018-01-01 AS DATE), a):date>
-- !query output
NULL


-- !query
select trunc(a, 'MM') from t
-- !query schema
struct<trunc(CAST(a AS DATE), MM):date>
-- !query output
NULL


-- !query
select trunc('2018-01-01', a) from t
-- !query schema
struct<trunc(CAST(2018-01-01 AS DATE), a):date>
-- !query output
NULL


-- !query
select unhex('-123')
-- !query schema
struct<unhex(-123):binary>
-- !query output
NULL


-- !query
select sha2(a, a) from t
-- !query schema
struct<sha2(CAST(a AS BINARY), CAST(a AS INT)):string>
-- !query output
NULL


-- !query
select get_json_object(a, a) from t
-- !query schema
struct<get_json_object(a, a):string>
-- !query output
NULL


-- !query
select json_tuple(a, a) from t
-- !query schema
struct<c0:string>
-- !query output
NULL


-- !query
select from_json(a, 'a INT') from t
-- !query schema
struct<from_json(a):struct<a:int>>
-- !query output
{"a":null}
