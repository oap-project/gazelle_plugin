- SPARK-3173 Timestamp support in the parser *** FAILED ***
- changing schema of state when restarting query - schema check off - state format version 1 *** FAILED ***
- timestamp type conversion *** FAILED ***
- SHOW PARTITIONS V1: SPARK-33591: null as a partition value *** FAILED ***
- Spark vectorized reader - with partition data column - select only top-level fields *** FAILED ***
- Spark vectorized reader - with partition data column - select one deep nested complex field after join *** FAILED ***
- Spark vectorized reader - with partition data column - select one deep nested complex field after outer join *** FAILED ***
- setAuthenticationConfigIfNeeded must set authentication if not set *** FAILED ***
- Write timestamps correctly with timestampFormat option and timeZone option *** FAILED ***
- exception mode for parsing date/timestamp string *** FAILED ***
- test SortMergeJoin (with spill) *** FAILED ***
- unsafe broadcast hash join updates peak execution memory *** FAILED ***
- unsafe broadcast hash outer join updates peak execution memory *** FAILED ***
- unsafe broadcast left semi join updates peak execution memory *** FAILED ***
- SPARK-23192: broadcast hint should be retained after using the cached data *** FAILED ***
- SPARK-23214: cached data should not carry extra hint info *** FAILED ***
- broadcast hint in SQL *** FAILED ***
- Broadcast timeout *** FAILED ***
- broadcast join where streamed side's output partitioning is HashPartitioning *** FAILED ***
- broadcast join where streamed side's output partitioning is PartitioningCollection *** FAILED ***
- BroadcastHashJoinExec output partitioning size should be limited with a config *** FAILED ***
- SPARK-8005 input_file_name *** FAILED ***
- SPARK-32516: legacy path option behavior in load() *** FAILED ***
- SPARK-32160: Disallow to create SparkSession in executors *** FAILED ***
- SPARK-32160: Allow to create SparkSession in executors if the config is set *** FAILED ***
- SPARK-32991: Use conf in shared state as the original configuration for RESET *** FAILED ***
- SPARK-32991: RESET should work properly with multi threads *** FAILED ***
- SPARK-33944: warning setting hive.metastore.warehouse.dir using session options *** FAILED ***
- SPARK-33944: no warning setting spark.sql.warehouse.dir using session options *** FAILED ***
- SPARK-10634 timestamp written and read as INT64 - truncation *** FAILED ***
- SPARK-10301 requested schema clipping - schemas with disjoint sets of fields *** FAILED ***
- SPARK-26677: negated null-safe equality comparison should not filter matched row groups *** FAILED ***
- returning batch for wide table *** FAILED ***
- SPARK-15370: COUNT bug in Aggregate *** FAILED ***
- date type - cast from timestamp *** FAILED ***
- datetime function - unix_date *** FAILED ***
- datetime function - to_date with format *** FAILED ***
- SELECT structFieldComplex.Value.`value_(2)` FROM tableWithSchema *** FAILED ***
- basic usage *** FAILED ***
- input row metrics *** FAILED ***
- verify ServerThread only accepts the first connection *** FAILED ***
- Give up splitting aggregate code if a parameter length goes over the limit *** FAILED ***
- Give up splitting subexpression code if a parameter length goes over the limit *** FAILED ***
- pivot with timestamp and count should not print internal representation *** FAILED ***
- Columnar Cache Plugin *** FAILED ***
- SPARK-28224: Aggregate sum big decimal overflow *** FAILED ***
- SPARK-28067: Aggregate sum should not return wrong results for decimal overflow *** FAILED ***
- describe *** FAILED ***
- SPARK-18350 show with session local timezone *** FAILED ***
- SPARK-18350 show with session local timezone, vertical = true *** FAILED ***
- SPARK-19372: Filter can be executed w/o generated code due to JVM code size limit *** FAILED ***
- SPARK-22271: mean overflows and returns null for some decimal variables *** FAILED ***
- UDF input_file_name() *** FAILED ***
- Spark vectorized reader - with partition data column - select only top-level fields *** FAILED ***
- Spark vectorized reader - with partition data column - select only expressions without references *** FAILED ***
- Spark vectorized reader - with partition data column - select one deep nested complex field after join *** FAILED ***
- Spark vectorized reader - with partition data column - select one deep nested complex field after outer join *** FAILED ***
- column type inference *** FAILED ***
- parse partitions *** FAILED ***
- SPARK-26327: FileSourceScanExec metrics *** FAILED ***
- SPARK-31159: compatibility with Spark 2.4 in reading dates/timestamps *** FAILED ***
- SPARK-31159: rebasing timestamps in write *** FAILED ***
- SPARK-31284, SPARK-31423: rebasing timestamps in write *** FAILED ***
- column type inference *** FAILED ***
- parse partitions *** FAILED ***
- Spark vectorized reader - with partition data column - select only top-level fields *** FAILED ***
- Spark vectorized reader - with partition data column - select one deep nested complex field after join *** FAILED ***
- Spark vectorized reader - with partition data column - select one deep nested complex field after outer join *** FAILED ***
- timeZone setting in dynamic partition writes *** FAILED ***
- ReadOnlySQLConf is correctly created at the executor side *** FAILED ***
- case-sensitive config should work for json schema inference *** FAILED ***
- SPARK-24727 CODEGEN_CACHE_MAX_ENTRIES is correctly referenced at the executor side *** FAILED ***
- SPARK-22219: refactor to control to generate comment *** FAILED ***
- SPARK-28939: propagate SQLConf also in conversions to RDD *** FAILED ***
- SPARK-30556 propagate local properties to subquery execution thread *** FAILED ***
- SPARK-22590 propagate local properties to broadcast execution thread *** FAILED ***
- SPARK-10634 timestamp written and read as INT64 - truncation *** FAILED ***
- SPARK-10301 requested schema clipping - schemas with disjoint sets of fields *** FAILED ***
- SPARK-26677: negated null-safe equality comparison should not filter matched row groups *** FAILED ***
- returning batch for wide table *** FAILED ***
- parquet timestamp conversion *** FAILED ***
- Check schemas for expression examples *** FAILED ***
- Generated code on driver should not embed platform-specific constant *** FAILED ***
- distributed test *** FAILED ***
- environmental variables *** FAILED ***
- BroadcastExchange should cancel the job group if timeout *** FAILED ***
- Spark vectorized reader - with partition data column - select only top-level fields *** FAILED ***
- Spark vectorized reader - with partition data column - select only expressions without references *** FAILED ***
- Spark vectorized reader - with partition data column - select one deep nested complex field after join *** FAILED ***
- Spark vectorized reader - with partition data column - select one deep nested complex field after outer join *** FAILED ***
- alternative output committer, merge schema *** FAILED ***
- alternative output committer, no merge schema *** FAILED ***
- Parquet output committer, merge schema *** FAILED ***
- Parquet output committer, no merge schema *** FAILED ***
- input_file_name, input_file_block_start, input_file_block_length - FileScanRDD *** FAILED ***
- unsafe broadcast hash join updates peak execution memory *** FAILED ***
- unsafe broadcast hash outer join updates peak execution memory *** FAILED ***
- unsafe broadcast left semi join updates peak execution memory *** FAILED ***
- SPARK-23192: broadcast hint should be retained after using the cached data *** FAILED ***
- SPARK-23214: cached data should not carry extra hint info *** FAILED ***
- broadcast hint in SQL *** FAILED ***
- Broadcast timeout *** FAILED ***
- broadcast join where streamed side's output partitioning is HashPartitioning *** FAILED ***
- broadcast join where streamed side's output partitioning is PartitioningCollection *** FAILED ***
- BroadcastHashJoinExec output partitioning size should be limited with a config *** FAILED ***
- columnar batch scan implementation *** FAILED ***
- Write timestamps correctly with timestampFormat option and timeZone option *** FAILED ***
- SPARK-15824 - Execute an INSERT wrapped in a WITH statement immediately *** FAILED ***
- union by name - type coercion *** FAILED ***
- SPARK-22520: support code generation for large CaseWhen *** FAILED ***
- SPARK-29894 test Codegen Stage Id in SparkPlanInfo *** FAILED ***
- hint merge *** FAILED ***
- hint merge - SQL *** FAILED ***
- log deprecation warnings *** FAILED ***
- Resolve join hint in CTE *** FAILED ***
- SPARK-23786: warning should be printed if CSV header doesn't conform to schema *** FAILED ***
- SPARK-23786: warning should be printed if CSV header doesn't conform to schema *** FAILED ***
- SPARK-23786: warning should be printed if CSV header doesn't conform to schema *** FAILED ***
- SPARK-30886 Deprecate two-parameter TRIM/LTRIM/RTRIM *** FAILED ***
- test log level *** FAILED ***
- SPARK-25602: SparkPlan.getByteArrayRdd should not consume the input when not necessary *** FAILED ***
- Cancelling stage in a query with Range. (whole-stage-codegen on) *** FAILED ***
- SPARK-20430 Initialize Range parameters in a driver side *** FAILED ***